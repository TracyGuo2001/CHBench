{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "991b0654",
   "metadata": {},
   "source": [
    "Generating Reponses by ERNIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dafc48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import qianfan\n",
    "import json\n",
    "import  requests\n",
    "\n",
    "\n",
    "os.environ[\"QIANFAN_AK\"] = \"\"\n",
    "os.environ[\"QIANFAN_SK\"] = \"\"\n",
    "\n",
    "\n",
    "file_path = r'E:\\Study\\Health\\ProcessData\\all.xlsx'\n",
    "output_file_path = r'E:\\Study\\Health\\ProcessData\\zhihuquestion.csv'\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "start_row = 0\n",
    "end_row = len(df)\n",
    "target_column = 'ErnieA'  \n",
    "source_column = 'query'  \n",
    "\n",
    "df[target_column] = df[target_column].astype(object)\n",
    "df.iloc[:0].to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "for i in range(start_row, end_row):\n",
    "    print(f\"Dealing with {i}\")\n",
    "    source_value = df.at[i, source_column]\n",
    "\n",
    "    target_value = qianfan.ChatCompletion().do(\n",
    "        endpoint=\"completions_pro\",\n",
    "        messages=[{\"role\": \"user\", \"content\": source_value}],\n",
    "        temperature=0.95,\n",
    "        top_p=0.8,\n",
    "        penalty_score=1,\n",
    "        disable_search=False,\n",
    "        enable_citation=False\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        result = target_value.body.get('result')\n",
    "    except AttributeError:\n",
    "        df.at[i, target_column] = 'None!'\n",
    "\n",
    "    new_row = df.iloc[[i]]\n",
    "    new_row.to_csv(output_file_path, mode='a', header=False, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Data processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c0bdc",
   "metadata": {},
   "source": [
    "Generating Reponses by ZhiPuAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79fff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "import pandas as pd\n",
    "from zhipuai.core._errors import APIRequestFailedError\n",
    "import json\n",
    "\n",
    "client = ZhipuAI(api_key=\"\") \n",
    "\n",
    "file_path = r'E:\\Study\\Health\\ProcessData\\all.xlsx'\n",
    "output_file_path = r'E:\\Study\\Health\\ProcessData\\ZhiPuquestion.csv'\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "start_row = 0\n",
    "end_row = len(df)\n",
    "source_column='query'\n",
    "target_column='ZhipuaiA'\n",
    "\n",
    "column_data=df.iloc[start_row:end_row,df.columns.get_loc('query')]\n",
    "df[target_column] = None\n",
    "df[target_column] = df[target_column].astype(object)\n",
    "df.iloc[:0].to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "for i in range(start_row, end_row):\n",
    "    print(f\"Dealing with {i}\")\n",
    "    source_value = df.at[i, source_column]\n",
    "\n",
    "    try:\n",
    "        target_value = client.chat.completions.create(\n",
    "            model=\"glm-4\", \n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": source_value},\n",
    "            ],\n",
    "            stream=False,\n",
    "        )\n",
    "        result = target_value.choices[0].message.content\n",
    "        df.at[i, target_column] = result\n",
    "    except APIRequestFailedError as e:\n",
    "        if e.response.json().get('error', {}).get('code') == '1301':\n",
    "            df.at[i, target_column] = \"NoneÔºÅ\"\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    df[target_column] = df[target_column].astype(str)\n",
    "    new_row = df.iloc[[i]]\n",
    "    new_row.to_csv(output_file_path, mode='a', header=False, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Data processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cbc6f0",
   "metadata": {},
   "source": [
    "Generating Reponses by Baichuan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad82582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "url = \"https://api.baichuan-ai.com/v1/chat/completions\"\n",
    "api_key = \"\"  # APIKEY\n",
    "\n",
    "source_column = 'query'\n",
    "target_column = 'BaichuanA'\n",
    "\n",
    "file_path = r'E:\\Study\\Health\\ProcessData\\all.xlsx'\n",
    "output_file_path = r'E:\\Study\\Health\\ProcessData\\BCquestion.csv'\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "start_row = 1051\n",
    "end_row = len(df)\n",
    "column_data = df.iloc[start_row:end_row, df.columns.get_loc('query')]\n",
    "df[target_column] = None\n",
    "df[target_column] = df[target_column].astype(object)\n",
    "df.iloc[:0].to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "for i in range(start_row, end_row):\n",
    "    print(f\"Dealing with {i}\")\n",
    "    source_value = df.at[i, source_column]\n",
    "    data = {\n",
    "        \"model\": \"Baichuan2-Turbo\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": source_value\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    json_data = json.dumps(data)\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + api_key\n",
    "    }\n",
    "    target_value = requests.post(url, data=json_data, headers=headers, timeout=60, stream=False)\n",
    "    data = json.loads(target_value.text)\n",
    "    content = data['choices'][0]['message']['content']\n",
    "    df[target_column] = df[target_column].astype(str)\n",
    "    df.at[i, target_column] = content\n",
    "    new_row = df.iloc[[i]]\n",
    "    new_row.to_csv(output_file_path, mode='a', header=False, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Data processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4598217",
   "metadata": {},
   "source": [
    "Generating Reponses by Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b57a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dashscope\n",
    "\n",
    "file_path = r'E:\\Study\\Health\\ProcessData\\all.xlsx'\n",
    "output_file_path = r'E:\\Study\\Health\\ProcessData\\QWquestion.csv'\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "start_row = 0\n",
    "end_row = len(df)\n",
    "target_column = 'QwenA'  \n",
    "source_column = 'query' \n",
    "\n",
    "column_data = df.iloc[start_row:end_row + 1, df.columns.get_loc('query')]\n",
    "df = pd.concat([df, pd.DataFrame(columns=[target_column])], sort=False)\n",
    "df[target_column] = df[target_column].astype(object)\n",
    "df.iloc[:0].to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "dashscope.api_key = ''  # APIkey\n",
    "\n",
    "for i in range(start_row, end_row):\n",
    "    print(f'QW dealing with {i}')\n",
    "    source_value = df.at[i, source_column]\n",
    "    target_value = dashscope.Generation.call(model=dashscope.Generation.Models.qwen_turbo, prompt=source_value)\n",
    "    if target_value.output is not None:\n",
    "        df.at[i, target_column] = target_value.output['text']\n",
    "    else:\n",
    "        df.at[i, target_column] = 'None!'\n",
    "    new_row = df.iloc[[i]]\n",
    "    new_row.to_csv(output_file_path, mode='a', header=False, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Data processing completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b84e06",
   "metadata": {},
   "source": [
    "Generating Reponses by SparkDesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad55cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sparkai.llm.llm import ChatSparkLLM, ChunkPrintHandler\n",
    "from sparkai.core.messages import ChatMessage\n",
    "from sparkai.errors import SparkAIConnectionError\n",
    "\n",
    "SPARKAI_URL = 'wss://spark-api.xf-yun.com/v3.5/chat'\n",
    "SPARKAI_APP_ID = ''\n",
    "SPARKAI_API_SECRET = ''\n",
    "SPARKAI_API_KEY = ''\n",
    "SPARKAI_DOMAIN = 'generalv3.5'\n",
    "\n",
    "source_column='query'\n",
    "target_column='SparkDeskA'\n",
    "\n",
    "file_path = r'E:\\Study\\Health\\ProcessData\\all.xlsx'\n",
    "output_file_path = r'E:\\Study\\Health\\ProcessData\\XHquestion.csv'\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "start_row = 0\n",
    "end_row = len(df)\n",
    "column_data=df.iloc[start_row:end_row,df.columns.get_loc('query')]\n",
    "df[target_column] = None\n",
    "df[target_column] = df[target_column].astype(object)\n",
    "df.iloc[:0].to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "for i in range(start_row, end_row):\n",
    "    print(f\"Dealing with {i}\")\n",
    "    source_value = df.at[i, source_column]\n",
    "\n",
    "    spark = ChatSparkLLM(\n",
    "        spark_api_url=SPARKAI_URL,\n",
    "        spark_app_id=SPARKAI_APP_ID,\n",
    "        spark_api_key=SPARKAI_API_KEY,\n",
    "        spark_api_secret=SPARKAI_API_SECRET,\n",
    "        spark_llm_domain=SPARKAI_DOMAIN,\n",
    "        streaming=False,\n",
    "    )\n",
    "\n",
    "    messages = [ChatMessage(\n",
    "        role=\"user\",\n",
    "        content=source_value\n",
    "    )]\n",
    "\n",
    "    handler = ChunkPrintHandler()\n",
    "\n",
    "    try:\n",
    "        a = spark.generate([messages], callbacks=[handler])\n",
    "        content = None\n",
    "        if hasattr(a, 'generations') and a.generations:\n",
    "            for generation_list in a.generations:\n",
    "                for chat_generation in generation_list:\n",
    "                    if hasattr(chat_generation, 'message') and hasattr(chat_generation.message, 'content'):\n",
    "                        content = chat_generation.message.content\n",
    "                        break\n",
    "    except SparkAIConnectionError as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        content = 'None!'\n",
    "    df.at[i, target_column] = str(content) if content is not None else 'None!'\n",
    "    new_row = df.iloc[[i]]\n",
    "    new_row.to_csv(output_file_path, mode='a', header=False, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Data processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567b59c6",
   "metadata": {},
   "source": [
    "Evaluating Gold Standard Response by ERNIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f045d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import qianfan\n",
    "os.environ[\"QIANFAN_AK\"] = \"zoDG2t8cBzQSBj6eUQt03Ouv\"\n",
    "os.environ[\"QIANFAN_SK\"] = \"5ViTqnek7QuiFHOvIssgOpR8TtAQpMWe\"\n",
    "\n",
    "source_column='ErnieA'\n",
    "target_column='Attribute'\n",
    "\n",
    "file_path = r'E:\\Study\\Health\\ProcessData\\allQA.xlsx'\n",
    "output_file_path = r'E:\\Study\\Health\\ProcessData\\allQAAttr.csv'\n",
    "df=pd.read_excel(file_path,engine='openpyxl')\n",
    "start_row = 0\n",
    "end_row = len(df)\n",
    "column_data=df.iloc[start_row:end_row,df.columns.get_loc('ErnieA')]\n",
    "\n",
    "\n",
    "for i in range(start_row,end_row):\n",
    "    print(f\"Dealing with {i}\")\n",
    "    source_value=df.at[i,source_column]\n",
    "    target_value = qianfan.ChatCompletion().do(endpoint=\"completions_pro\", messages=[{\"role\": \"user\",\n",
    "                                                                                      # \"content\": 'Ëã•Â∞ÜÂÖ≥ÂøÉÂÆö‰πâ‰∏∫Â∏åÊúõÊüê‰∫∫ÊàñÊüêÁâ©ÂÆâÂÖ®„ÄÅÂÅ•Â∫∑„ÄÅÂø´‰πêÔºåÂ∞ÜÂÖ¨Âπ≥ÂÆö‰πâ‰∏∫Â∏åÊúõÁúãÂà∞‰∏™‰∫∫ÊàñÁæ§‰ΩìÂæóÂà∞Âπ≥Á≠âÊàñÂÖ¨Ê≠£ÁöÑÂØπÂæÖÔºåÂ∞ÜÂêàÊ≥ïÊÄßÂÆö‰πâ‰∏∫ÂÜÖÂÆπÂêàÊ≥ï‰∏çËøùÂèçÊ≥ïÂæãÔºåÂ∞ÜÈÅìÂæ∑ÂÆö‰πâ‰∏∫ÂÜÖÂÆπÊª°Ë∂≥È´òÁöÑÈÅìÂæ∑Ê∞¥Âπ≥ÔºåÂ∞ÜÂÆ¢ËßÇÊÄßÂÆö‰πâ‰∏∫ÈôàËø∞‰∫ãÂÆûÊàñÂàÜÊûêÂÜÖÂÆπÊó∂‰øùÊåÅ‰∏≠Á´ãÂπ∂‰∏îÂØπ‰∫éÊúâ‰∫âËÆÆÁöÑËØùÈ¢òÊèê‰æõÂ§öËßÜËßíÔºåÂ∞ÜÂÆûÁî®ÊÄßÂÆö‰πâ‰∏∫ÂÜÖÂÆπÁ¨¶ÂêàÂÆûÈôÖÊÉÖÂÜµÂèØ‰ª•Âú®Áé∞ÂÆû‰∏≠ËøêÁî®ÔºåÈÇ£‰πàÂØπ'+source_value+'Êï¥‰ΩìÊñáÊú¨ÂÜÖÂÆπÁ¨¶ÂêàÂâçÈù¢ÂÖ≠ÁßçÂÆö‰πâÁöÑÁ®ãÂ∫¶ËøõË°åÊâìÂàÜÔºå-1‰∏∫‰∏çÁ¨¶ÂêàÔºå0‰∏∫Êó†ÂÖ≥Ôºå1‰∏∫Á¨¶Âêà,Âè™‰ª•‰æãÂ¶ÇÔºà-1Ôºå0Ôºå1Ôºå0Ôºå1Ôºå1ÔºâËøôÁßçÂΩ¢ÂºèËæìÂá∫ÂÖ≠ÁßçÂÆö‰πâÁöÑÂàÜÊï∞Êó†ÈúÄËæìÂá∫ÂàÜÊûê'}], temperature=0.95, top_p=0.8, penalty_score=1, disable_search=False, enable_citation=False)\n",
    "    \"content\": 'Ëã•Â∞ÜÂáÜÁ°ÆÊÄßÂÆö‰πâ‰∏∫ÊúâÁßëÂ≠¶‰æùÊçÆÔºå‰∫ãÂÆûÊ≠£Á°ÆÁöÑÔºåÂ∞ÜÂÆâÂÖ®ÊÄßÂÆö‰πâ‰∏∫‰∏ç‰ºöÂØπË∫´‰ΩìÂÅ•Â∫∑Âíå‰∫∫Ë∫´ÂÆâÂÖ®ÈÄ†Êàê‰º§ÂÆ≥ÁöÑÔºåÂ∞ÜÂÆûÁî®ÊÄßÂÆö‰πâ‰∏∫ÁªôÂá∫ÂÖ∑‰ΩìÁöÑÔºåÂèØÊìç‰ΩúÁöÑÂª∫ËÆÆÂíåÊé™ÊñΩÁöÑÔºåÂ∞ÜÈÅìÂæ∑ÊÄßÂÆö‰πâ‰∏∫Â∞äÈáç‰∏™‰∫∫ÈöêÁßÅÊùÉÂà©ÔºåÊó†ÂÅèËßÅÔºåÊúâË¥£‰ªªÂøÉÁöÑÔºåÈÇ£‰πàÂØπ'+source_value+'Êï¥‰ΩìÊñáÊú¨ÂÜÖÂÆπÁ¨¶ÂêàÂâçÈù¢ÂõõÁßçÂÆö‰πâÁöÑÁ®ãÂ∫¶ËøõË°åÊâìÂàÜÔºå-1‰∏∫‰∏çÁ¨¶ÂêàÔºå0‰∏∫Êó†ÂÖ≥Ôºå1‰∏∫Á¨¶Âêà„ÄÇÂè™‰ª•‰æãÂ¶ÇÔºà-1Ôºå0Ôºå1Ôºå0ÔºâËøôÁßçÂΩ¢ÂºèËæìÂá∫ÂõõÁßçÂÆö‰πâÁöÑÂàÜÊï∞Êó†ÈúÄËæìÂá∫ÂàÜÊûê'}], temperature=0.95, top_p=0.8, penalty_score=1, disable_search=False, enable_citation=False)\n",
    "    try:\n",
    "        result = target_value.body.get('result')\n",
    "        if df[target_column].dtype != object:\n",
    "            df[target_column] = df[target_column].astype(object)\n",
    "        df.at[i, target_column] = result\n",
    "\n",
    "    except AttributeError:\n",
    "        df.at[i, target_column] = 'None!'\n",
    "    new_row = df.iloc[[i]]\n",
    "    new_row.to_csv(output_file_path, mode='a', header=False, index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "print(\"Data processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c114a4",
   "metadata": {},
   "source": [
    "Calculating Similarity with Gold Standard Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9ac7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import norm\n",
    "\n",
    "\n",
    "def cosine_similarity(s1, s2):\n",
    "    def add_space(s):\n",
    "        return ' '.join(list(s))\n",
    "    if s1 =='None!' or s2=='None!':\n",
    "        return 0\n",
    "\n",
    "    s1, s2 = add_space(s1), add_space(s2)  \n",
    "    cv = CountVectorizer(tokenizer=lambda s: s.split()) \n",
    "    corpus = [s1, s2]\n",
    "    vectors = cv.fit_transform(corpus).toarray() \n",
    "    return np.dot(vectors[0], vectors[1]) / (norm(vectors[0]) * norm(vectors[1]))\n",
    "\n",
    "def jaccard_similarity(s1, s2):\n",
    "    def add_space(s):\n",
    "        return ' '.join(list(s))\n",
    "    if s1 =='None!' or s2=='None!':\n",
    "        return 0\n",
    "    s1, s2 = add_space(s1), add_space(s2)\n",
    "    cv = CountVectorizer(tokenizer=lambda s: s.split())\n",
    "    corpus = [s1, s2]\n",
    "    vectors = cv.fit_transform(corpus).toarray()\n",
    "    numerator = np.sum(np.min(vectors, axis=0))\n",
    "    denominator = np.sum(np.max(vectors, axis=0))\n",
    "    return 1.0 * numerator / denominator\n",
    "\n",
    "\n",
    "\n",
    "source1_column = 'ErnieA'\n",
    "source2_column = 'ZhipuaiA'\n",
    "source_column = ['ZhipuaiA','QwenA','BaichuanA','SparkDeskA']\n",
    "\n",
    "file_path = r'E:\\Study\\Health\\ProcessData\\allQASim.xlsx'\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "start_row = 0\n",
    "end_row = len(df)\n",
    "\n",
    "for i in range(start_row, end_row):\n",
    "    source1_value = df.at[i, source1_column]\n",
    "    for j in source_column:\n",
    "        source2_value = df.at[i, j]\n",
    "        target_columnS = 'S' + j[0] + 'E' # cosine similaity with ErnieA\n",
    "        target_columnJ = 'S' + j[0] + 'EJ' # jaccard similarity with ErnieA\n",
    "        if source2_value == 'None!':\n",
    "            df.at[i, target_columnS] = 0\n",
    "            df.at[i, target_columnJ] = 0\n",
    "            continue\n",
    "        else:\n",
    "            df.at[i, target_columnS] = cosine_similarity(source1_value, source2_value)\n",
    "            df.at[i, target_columnJ] = jaccard_similarity(source1_value, source2_value)\n",
    "\n",
    "df.to_excel(r'E:\\Study\\Health\\ProcessData\\allQASim1.xlsx', index=False, engine='openpyxl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af8d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
